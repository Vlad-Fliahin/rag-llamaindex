{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de903ecf-4f6f-4a5b-81ac-bcd8c6e90735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import logging\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import tomli as tomlib\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from llama_index.core import Settings, VectorStoreIndex, get_response_synthesizer, PromptTemplate\n",
    "from llama_index.core.node_parser import TokenTextSplitter, SentenceSplitter\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.indices.vector_store.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor, NERPIINodePostprocessor, PrevNextNodePostprocessor\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core.agent import AgentRunner, ReActAgentWorker\n",
    "from llama_index.core.base.llms.types import ChatMessage\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.vector_stores.neo4jvector import Neo4jVectorStore\n",
    "from llama_index.agent.openai import OpenAIAgentWorker\n",
    "from trulens.core import TruSession\n",
    "from trulens.core.feedback.feedback import Feedback\n",
    "from trulens.providers.openai import OpenAI as OpenAIProvider\n",
    "from trulens.providers.huggingface import Huggingface\n",
    "from trulens.apps.llamaindex import TruLlama\n",
    "from trulens.dashboard import run_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b17fc34-c252-4ade-be5f-22ab94cf92fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6e35718-5c74-48ef-a7b4-94f685feb8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse configuration\n",
    "with open('../pyproject.toml', \"rb\") as file:\n",
    "    CFG = tomlib.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f769d41-81fa-4f8a-b250-eaa27f4ff468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Use your token here\n",
    "login(token=CFG['configuration']['models']['hf_token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f31f8a1-92af-4804-95a0-47de7afb1809",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76ebcba6-1073-4b10-8056-fd912a9a6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "with open(CFG['configuration']['data']['dataset_path'], 'rb') as file:\n",
    "    dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c458eadf-52d8-4d4b-931a-9d33f9ebf4d2",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37c4918-781d-4850-bb53-08b174093834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the existing neo4j vector index\n",
    "vector_store = Neo4jVectorStore(\n",
    "    username=CFG['configuration']['db']['username'],\n",
    "    password=CFG['configuration']['db']['password'],\n",
    "    url=CFG['configuration']['db']['url'],\n",
    "    embedding_dimension=CFG['configuration']['embedding_dimension'],\n",
    "    distance_strategy=CFG['configuration']['distance_strategy'],\n",
    "    index_name=CFG['configuration']['db']['index_name'],\n",
    "    text_node_property=CFG['configuration']['db']['text_node_property']\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc0c7f6-402b-4dec-a214-dc73ecf255fc",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "14dd2bc5-7cb3-4238-922d-44e50a4b1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "llm = OpenAI(\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'), \n",
    "    model=CFG['configuration']['models']['llm'],\n",
    "    temperature=CFG['configuration']['models']['temperature']\n",
    ")\n",
    "\n",
    "embed_model = OpenAIEmbedding(\n",
    "    model=CFG['configuration']['models']['embedding_model'],\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    dimensions=CFG['configuration']['embedding_dimension']\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b32586e-6044-4bd2-8edf-8b61bd5e96f6",
   "metadata": {},
   "source": [
    "### Opensource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c84ed8e9-0c6b-46c0-80b4-27bf690ac552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f89362be43451b8c26b7779b669f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an AI assistant that answers questions in a friendly manner, based on the given source documents. Here are some rules you always follow:\n",
    "- Generate human readable output, avoid creating output with gibberish text.\n",
    "- Generate only the requested output, don't include any other language before or after the requested output.\n",
    "- Never say thank you, that you are happy to help, that you are an AI agent, etc. Just answer directly.\n",
    "- Generate professional language typically used in business documents in North America.\n",
    "- Never generate offensive or foul language.\n",
    "\"\"\"\n",
    "\n",
    "query_wrapper_prompt = PromptTemplate(\n",
    "    \"<|start_header_id|>system<|end_header_id|>\\n\" + SYSTEM_PROMPT + \"<|eot_id|><|start_header_id|>user<|end_header_id|>{query_str}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\n",
    ")\n",
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    context_window=CFG['configuration']['models']['context_window'],\n",
    "    max_new_tokens=CFG['configuration']['models']['max_new_tokens'],\n",
    "    generate_kwargs={\"temperature\": CFG['configuration']['models']['temperature'], \"do_sample\": False},\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=CFG['configuration']['models']['llm_hf'],\n",
    "    model_name=CFG['configuration']['models']['llm_hf'],\n",
    "    device_map=\"cuda:0\",\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16}\n",
    ")\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fe2c36-7d91-420e-a842-d74172432d04",
   "metadata": {},
   "source": [
    "## QueryEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cae3a64e-62a2-40c3-8c33-35b146b4ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create query engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c36e50f9-e696-472b-8533-17ab3973e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukraine-boats-3, 0.8536546230316162\n",
      "ukraine-boats-4, 0.8363556861877441\n",
      "The primary focus of Ukraine Boats Inc. is on designing and manufacturing boats that incorporate eco-friendly technologies, ensuring compliance with maritime safety standards, and expanding their market presence in Europe, North America, and Asia. They also emphasize customer relationships, quality control in production, and initiatives aimed at reducing their carbon footprint and making boating more accessible.\n"
     ]
    }
   ],
   "source": [
    "# custom question\n",
    "response = query_engine.query(\"What is the primary focus of Ukraine Boats Inc.?\")\n",
    "\n",
    "# get similarity scores\n",
    "for node in response.source_nodes:\n",
    "    print(f'{node.node.id_}, {node.score}')\n",
    "    \n",
    "# predicted answer\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8896e13d-e3fb-42ba-8c51-3d69e0031c45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Custom query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d347a7d0-20ea-4e76-97a7-72e8aa5606c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=CFG['configuration']['similarity_top_k'],\n",
    "    vector_store_query_mode=CFG['configuration']['vector_store_query_mode']\n",
    ")\n",
    "\n",
    "# similarity threshold\n",
    "similarity_postprocessor = SimilarityPostprocessor(similarity_cutoff=CFG['configuration']['similarity_cutoff'])\n",
    "\n",
    "# custom response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=CFG['configuration']['response_mode']\n",
    ")\n",
    "\n",
    "# combine custom query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[similarity_postprocessor],\n",
    "    response_synthesizer=response_synthesizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6997610f-09fc-4c05-8a7e-998b0d69ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom questions\n",
    "response = query_engine.query(\"What is the primary focus of Ukraine Boats Inc.?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "66a75779-ef82-42e3-a1d7-0dc56597ab85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukraine-boats-3, 0.8536546230316162\n",
      "ukraine-boats-4, 0.8363556861877441\n",
      "ukraine-boats-2, 0.8338797092437744\n",
      "ukraine-boats-0, 0.8337738513946533\n",
      "ukraine-boats-5, 0.83036208152771\n",
      "ukraine-boats-6, 0.8298962116241455\n",
      "ukraine-boats-7, 0.8119900226593018\n",
      "ukraine-boats-9, 0.7885396480560303\n",
      "ukraine-boats-1, 0.7823765277862549\n",
      "ukraine-boats-10, 0.7761285305023193\n"
     ]
    }
   ],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(f'{node.node.id_}, {node.score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0669fecc-5c36-44ee-a0ff-3d6b344c3354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The primary focus of Ukraine Boats Inc. is to manufacture and supply high-quality boats and maritime solutions, specializing in recreational, commercial, and luxury vessels. The company emphasizes blending traditional craftsmanship with modern technology while integrating eco-friendly practices and ensuring compliance with maritime safety standards.'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659623f1-3959-4b34-9424-3662bbbca69e",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b66ab693-0453-4338-bc15-2b1ed7955703",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_SYSTEM_PROMPT = \"You are a helpful human assistant. You always call the retrieve_semantically_similar_data tool before answering any questions. If the answer to the questions couldn't be found using the tool, just respond with `Didn't find relevant information`.\"\n",
    "TOOL_NAME = \"retrieve_semantically_similar_data\"\n",
    "TOOL_DESCRIPTION = \"Provides additional information about the companies. Input: string\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c926921f-17fc-4626-ac4a-5ccf903e511f",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b236466c-cd85-415f-9448-922675ad1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent worker\n",
    "agent_worker = OpenAIAgentWorker.from_tools(\n",
    "    [\n",
    "        QueryEngineTool.from_defaults(\n",
    "            query_engine=query_engine,\n",
    "            name=TOOL_NAME,\n",
    "            description=TOOL_DESCRIPTION,\n",
    "            return_direct=False,\n",
    "        )\n",
    "    ],\n",
    "    system_prompt=AGENT_SYSTEM_PROMPT,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_function_calls=CFG['configuration']['max_function_calls']\n",
    ")\n",
    "\n",
    "# agent runner\n",
    "agent = AgentRunner(agent_worker=agent_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e0baa-ed37-4984-8848-fc88bf8e5a62",
   "metadata": {},
   "source": [
    "### Opensource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b8aec6d5-6908-42e2-9ad5-088a7232187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_worker = ReActAgentWorker.from_tools(\n",
    "    [\n",
    "        QueryEngineTool.from_defaults(\n",
    "            query_engine=query_engine,\n",
    "            name=TOOL_NAME,\n",
    "            description=TOOL_DESCRIPTION,\n",
    "            return_direct=False,\n",
    "        )\n",
    "    ],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    chat_history=[ChatMessage(content=AGENT_SYSTEM_PROMPT, role=\"system\")]\n",
    ")\n",
    "\n",
    "# agent runner\n",
    "agent = AgentRunner(agent_worker=agent_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d157d-32d2-4d3b-b02a-b9f0449034a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9339e1a-e3d2-4413-a71e-33f5564a0ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert your next message: Hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:04:29.117|User: Hi\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: retrieve_semantically_similar_data\n",
      "Action Input: {'input': 'hello world', 'num_beams': 5}\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mObservation: Empty Response\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I still need more information to answer the question. The tool did not provide any useful output. I'll try to gather more context.\n",
      "Action: retrieve_semantically_similar_data\n",
      "Action Input: {'input': 'hello world', 'num_beams': 5}\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mObservation: Empty Response\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I still don't have enough information to answer the question. The tool did not provide any useful output. I'll try to gather more context.\n",
      "Action: retrieve_semantically_similar_data\n",
      "Action Input: {'input': 'hello world', 'num_beams': 5}\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mObservation: Empty Response\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I'm starting to think that the tool is not the best approach to answer this question. The user's input \"hello world\" is very general and the tool is not providing any useful output. I'll try to think of a different approach.\n",
      "Answer: Hello, how can I assist you today?\n",
      "\u001b[0m16:04:37.764|Agent: Hello, how can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert your next message: Do you know anything about the city solve?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:05:08.756|User: Do you know anything about the city solve?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: retrieve_semantically_similar_data\n",
      "Action Input: {'input': 'solve city'}\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mObservation: \n",
      "\n",
      "CitySolve Municipal Services is the lifeline of New Urbania, addressing a wide range of city-level concerns and providing prompt solutions to residents' everyday needs.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: CitySolve Municipal Services is a city-level organization that provides solutions to residents' everyday needs in New Urbania.\n",
      "\u001b[0m16:05:13.003|Agent: CitySolve Municipal Services is a city-level organization that provides solutions to residents' everyday needs in New Urbania.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert your next message: What is the primary focus of Ukraine Boats Inc.?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:05:34.892|User: What is the primary focus of Ukraine Boats Inc.?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: retrieve_semantically_similar_data\n",
      "Action Input: {'input': 'Ukraine Boats Inc.'}\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mObservation: \n",
      "\n",
      "Ukraine Boats Inc. is a premier manufacturer and supplier of high-quality boats and maritime solutions based in Odessa, Ukraine. The company prides itself on blending traditional craftsmanship with modern technology to serve clients worldwide. Founded in 2005, the company has grown to be a leader in the boating industry, specializing in recreational, commercial, and luxury vessels.\n",
      "\n",
      "The company has successfully delivered a range of boats and solutions to various clients, including Blue Horizon Fisheries, Azure Seas Luxury Charters, Coastal Safety Patrol, EcoTrade Logistics, Team HydroBlitz Racing, and Paradise Resorts International. These clients have reported significant benefits from working with Ukraine Boats Inc., including increased efficiency, reduced costs, and enhanced customer satisfaction.\n",
      "\n",
      "Ukraine Boats Inc. offers a range of products and services, including luxury yachts, commercial boats, and accessories. The company's products are designed to meet the specific needs of each client, and its team of experts works closely with clients to ensure that every boat is tailored to their requirements.\n",
      "\n",
      "Some of the company's notable products include the Odessa Opulence 5000, a state-of-the-art luxury yacht, and the Maritime Hauler 7000, a robust cargo ship. The company also offers boat customization packages, annual maintenance plans, and other services to support its clients' needs.\n",
      "\n",
      "Overall, Ukraine Boats Inc. is a trusted and reliable partner for clients seeking high-quality boats and maritime solutions.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Ukraine Boats Inc. is a premier manufacturer and supplier of high-quality boats and maritime solutions based in Odessa, Ukraine, blending traditional craftsmanship with modern technology to serve clients worldwide.\n",
      "\u001b[0m16:05:53.311|Agent: Ukraine Boats Inc. is a premier manufacturer and supplier of high-quality boats and maritime solutions based in Odessa, Ukraine, blending traditional craftsmanship with modern technology to serve clients worldwide.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert your next message: Do you know anything about the government company city solve?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:06:09.949|User: Do you know anything about the government company city solve?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is English. I need to use a tool to help me answer the question.\n",
      "Action: retrieve_semantically_similar_data\n",
      "Action Input: {'input': AttributedDict([('title', 'CitySolve'), ('type', 'string')])}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Error: 2 validation errors for QueryStartEvent\n",
      "query.str\n",
      "  Input should be a valid string [type=string_type, input_value=AttributedDict([('title',...'), ('type', 'string')]), input_type=AttributedDict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/string_type\n",
      "query.QueryBundle.query_str\n",
      "  Field required [type=missing, input_value=AttributedDict([('title',...'), ('type', 'string')]), input_type=AttributedDict]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/missing\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mObservation: Error: Could not parse output. Please follow the thought-action-input format. Try again.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I understand that the tool retrieve_semantically_similar_data requires a specific input format. I will make sure to follow the correct format.\n",
      "Action: retrieve_semantically_similar_data\n",
      "Action Input: {'title': 'CitySolve', 'type': 'string'}\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mObservation: \n",
      "\n",
      "CitySolve Municipal Services is a government-owned and operated company that serves as the backbone of New Urbania's civic infrastructure, addressing a wide range of city-level concerns.\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: CitySolve Municipal Services is a government-owned and operated company that serves as the backbone of New Urbania's civic infrastructure, addressing a wide range of city-level concerns.\n",
      "\u001b[0m16:06:17.799|Agent: CitySolve Municipal Services is a government-owned and operated company that serves as the backbone of New Urbania's civic infrastructure, addressing a wide range of city-level concerns.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert your next message: Thanks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:06:34.232|User: Thanks\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: CitySolve Municipal Services is a government-owned and operated company that serves as the backbone of New Urbania's civic infrastructure, addressing a wide range of city-level concerns.\n",
      "\u001b[0m16:06:35.734|Agent: CitySolve Municipal Services is a government-owned and operated company that serves as the backbone of New Urbania's civic infrastructure, addressing a wide range of city-level concerns.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# get user input\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     current_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInsert your next message:\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS.\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|User: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     response \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mchat(current_message)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-llamaindex-F9o6lAMf-py3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/rag-llamaindex-F9o6lAMf-py3.11/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # get user input\n",
    "    current_message = input('Insert your next message:')\n",
    "    print(f'{datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]}|User: {current_message}')\n",
    "\n",
    "    response = agent.chat(current_message)\n",
    "    print(f'{datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]}|Agent: {response.response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b56bc47-3394-4d04-8b20-3137df481b95",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ff210c6-1133-4c5b-8076-ca91d7574ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "tru = TruSession()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "464d17db-e823-4de7-92b3-8d9d9367b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"gpt-4o-mini-custom-retriever-added-tool-inputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50d9a626-ee78-42d0-8603-59300058a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = OpenAIProvider(\n",
    "    model_engine=CFG['configuration']['models']['llm_evaluation']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01d67c0a-e59e-4a1b-9ec0-a850ff44aec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Context Relevance, input context will be set to __record__.calls[-1].rets.source_nodes[:].node.text .\n",
      "✅ In Groundedness, input source will be set to __record__.calls[-1].rets.source_nodes[:].node.text.collect() .\n",
      "✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "context_selection = TruLlama.select_source_nodes().node.text\n",
    "\n",
    "# context relevance (for each of the context chunks)\n",
    "f_context_relevance = (\n",
    "    Feedback(\n",
    "        provider.context_relevance, name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(context_selection)\n",
    ")\n",
    "\n",
    "# groundedness\n",
    "f_groundedness_cot = (\n",
    "    Feedback(\n",
    "        provider.groundedness_measure_with_cot_reasons, name=\"Groundedness\"\n",
    "    )\n",
    "    .on(context_selection.collect())\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# answer relevance between overall question and answer\n",
    "f_qa_relevance = (\n",
    "    Feedback(\n",
    "        provider.relevance_with_cot_reasons, name=\"Answer Relevance\"\n",
    "    )\n",
    "    .on_input_output()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4bd4f55a-25e3-4726-ba69-ee6beb3f15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TruLlama agent\n",
    "tru_agent = TruLlama(\n",
    "    agent,\n",
    "    app_name=experiment_name,\n",
    "    tags=\"agent testing\",\n",
    "    feedbacks=[f_qa_relevance, f_context_relevance, f_groundedness_cot],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7c764da5-6326-454f-ae33-d2e9ea690e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components:\n",
      "\tTruLlama (Custom) at 0x7f57b7bff700 with path __app__\n",
      "\tAgentRunner (Custom) at 0x7f57b6916090 with path __app__.app\n",
      "\tChatMemoryBuffer (Custom) at 0x7f57b77ae4e0 with path __app__.app.memory\n",
      "\tSimpleChatStore (Custom) at 0x7f57b77ae170 with path __app__.app.memory.chat_store\n",
      "\n",
      "Methods:\n",
      "Object at 0x7f57b77ae4e0:\n",
      "\t<function BaseChatStoreMemory.put at 0x7f58a685ccc0> with path __app__.app.memory\n",
      "\t<function BaseMemory.put at 0x7f58a685c4a0> with path __app__.app.memory\n",
      "Object at 0x7f57b6916090:\n",
      "\t<function AgentRunner.chat at 0x7f58a4fe8900> with path __app__.app\n",
      "\t<function AgentRunner.stream_chat at 0x7f58a4fe8680> with path __app__.app\n",
      "\t<function AgentRunner.achat at 0x7f58a4fe8f40> with path __app__.app\n",
      "\t<function AgentRunner.astream_chat at 0x7f58a4fe9300> with path __app__.app\n",
      "\t<function BaseQueryEngine.query at 0x7f58a6ce96c0> with path __app__.app\n",
      "\t<function BaseQueryEngine.aquery at 0x7f58a6ce9940> with path __app__.app\n",
      "\t<function BaseQueryEngine.synthesize at 0x7f58a6ce99e0> with path __app__.app\n",
      "\t<function BaseQueryEngine.asynthesize at 0x7f58a6ce9760> with path __app__.app\n",
      "\t<function BaseQueryEngine.retrieve at 0x7f58a6ce9a80> with path __app__.app\n",
      "\t<function BaseChatEngine.chat at 0x7f58a67af100> with path __app__.app\n",
      "\t<function BaseAgent.stream_chat at 0x7f58a56caf20> with path __app__.app\n",
      "\t<function BaseChatEngine.achat at 0x7f58a67af240> with path __app__.app\n",
      "\t<function BaseAgent.astream_chat at 0x7f58a56cb1a0> with path __app__.app\n",
      "\t<function BaseChatEngine.stream_chat at 0x7f58a67af1a0> with path __app__.app\n",
      "\t<function BaseChatEngine.astream_chat at 0x7f58a67af2e0> with path __app__.app\n"
     ]
    }
   ],
   "source": [
    "tru_agent.print_instrumented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "21e886c8-e0a9-4296-aa38-efaf1f7de123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the primary focus of Ukraine Boats Inc.?\n",
      "=== Calling Function ===\n",
      "Calling function: retrieve_semantically_similar_data with args: {\"input\":\"Ukraine Boats Inc.\"}\n",
      "Got output: Ukraine Boats Inc. is a premier manufacturer and supplier of high-quality boats and maritime solutions based in Odessa, Ukraine. Founded in 2005, the company specializes in recreational, commercial, and luxury vessels, blending traditional craftsmanship with modern technology. It has established a strong market presence in Europe, North America, and Asia, supported by partnerships with distribution companies like Baltic Marine Distributors in Germany, OceanCraft LLC in the USA, and Yokohama SeaTech in Japan.\n",
      "\n",
      "The company is organized into several departments, including Engineering, Sales and Marketing, Production, and Customer Service, each with specific responsibilities to ensure efficient operations and customer satisfaction. Ukraine Boats Inc. is committed to sustainability through initiatives like the Green Maritime Initiative, aiming to reduce its carbon footprint by incorporating renewable energy solutions in its fleet.\n",
      "\n",
      "The product lineup includes recreational boats such as the WaveRunner X200 and AquaCruise 350, luxury yachts like the Odessa Opulence 5000, and commercial vessels such as the Maritime Hauler 7000. The company also offers customization options, maintenance plans, and a range of accessories to enhance the boating experience.\n",
      "\n",
      "With a focus on innovation, Ukraine Boats Inc. has participated in various competitions, achieving recognition for its eco-friendly designs and luxurious offerings. The company prides itself on its customer service, providing post-sale assistance and extended warranty packages to ensure client satisfaction.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% 1/10 [00:21<03:15, 21.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the price range for recreational boats offered by Ukraine Boats Inc.?\n",
      "=== Calling Function ===\n",
      "Calling function: retrieve_semantically_similar_data with args: {\"input\":\"price range for recreational boats offered by Ukraine Boats Inc.\"}\n",
      "Got output: The price range for recreational boats offered is $32,000 to $55,000.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% 2/10 [00:39<02:33, 19.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Which manufacturing facility focuses on bespoke yachts and customizations?\n",
      "=== Calling Function ===\n",
      "Calling function: retrieve_semantically_similar_data with args: {\"input\":\"manufacturing facility bespoke yachts customizations\"}\n",
      "Got output: The manufacturing facility dedicated to bespoke yachts and high-end customizations is the Lviv Custom Craft Workshop. This workshop focuses on creating one-off designs tailored to client specifications, utilizing handcrafted woodwork and premium materials imported from Italy.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% 3/10 [00:59<02:18, 19.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the warranty coverage offered for boats by Ukraine Boats Inc.?\n",
      "=== Calling Function ===\n",
      "Calling function: retrieve_semantically_similar_data with args: {\"input\":\"warranty coverage for boats by Ukraine Boats Inc.\"}\n",
      "Got output: All boats come with a 5-year warranty covering manufacturing defects. Additionally, engines are covered under a separate 3-year engine performance guarantee.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% 4/10 [01:08<01:33, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Which client used the Neptune Voyager catamaran, and what was the impact on their business?\n",
      "=== Calling Function ===\n",
      "Calling function: retrieve_semantically_similar_data with args: {\"input\":\"Neptune Voyager catamaran client impact on business\"}\n",
      "Got output: The deployment of 10 Neptune Voyager catamarans significantly enhanced the business for Paradise Resorts International in the Bahamas. The impact included a 45% increase in resort bookings, attributed to the popularity of the boat tours. The catamarans also earned the \"Best Tourism Experience\" award at the Caribbean Hospitality Awards and improved guest satisfaction ratings by 35%. The Neptune Voyager became the flagship attraction for the resort, with guests expressing enthusiasm about the unforgettable marine views and luxurious comfort.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% 5/10 [01:50<02:04, 24.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What award did the SolarGlide EcoBoat win at the Global Marine Design Challenge?\n",
      "=== Calling Function ===\n",
      "Calling function: retrieve_semantically_similar_data with args: {\"input\":\"SolarGlide EcoBoat Global Marine Design Challenge award\"}\n",
      "Got output: The SolarGlide EcoBoat won the **Best Eco-Friendly Design** category at the Global Marine Design Challenge in 2022 for its innovative solar energy system and zero-emission operation.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% 6/10 [02:15<01:39, 24.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: How has the Arctic Research Consortium benefited from the Poseidon Explorer?\n",
      "=== Calling Function ===\n",
      "Calling function: retrieve_semantically_similar_data with args: {\"input\":\"Arctic Research Consortium Poseidon Explorer benefits\"}\n",
      "Got output: The Poseidon Explorer provided significant benefits to the Arctic Research Consortium, including:\n",
      "\n",
      "- Successful completion of 5 Arctic research missions, leading to the collection of over 2,000 unique ice core samples.\n",
      "- A 60% improvement in data collection efficiency, facilitated by onboard autonomous navigation systems.\n",
      "- Enhanced safety for researchers operating in extreme conditions, thanks to its durable design and advanced technology.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% 7/10 [02:24<00:59, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What is the price of the Odessa Opulence 5000 luxury yacht?\n",
      "=== Calling Function ===\n",
      "Calling function: retrieve_semantically_similar_data with args: {\"input\":\"Odessa Opulence 5000 luxury yacht price\"}\n",
      "Got output: Starting at $1,500,000.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% 8/10 [02:36<00:34, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: Which features make the WaveRunner X200 suitable for watersports?\n",
      "=== Calling Function ===\n",
      "Calling function: retrieve_semantically_similar_data with args: {\"input\":\"WaveRunner X200 features for watersports\"}\n",
      "Got output: The WaveRunner X200 is designed for high-speed performance and durability in watersport racing. Key features include enhanced turbocharged engines and aerodynamic hull modifications, which contribute to its competitive edge on the water. These specifications enable teams to achieve superior speed and maneuverability, making it an ideal choice for dominating regional races.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% 9/10 [02:43<00:14, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added user message to memory: What sustainability initiative is Ukraine Boats Inc. pursuing?\n",
      "=== Calling Function ===\n",
      "Calling function: retrieve_semantically_similar_data with args: {\"input\":\"sustainability initiative Ukraine Boats Inc.\"}\n",
      "Got output: The sustainability initiative at Ukraine Boats Inc. is the **Green Maritime Initiative (GMI)**, which aims to reduce the carbon footprint by incorporating renewable energy solutions in 50% of the fleet by 2030. Additionally, the company promotes the **SolarGlide EcoBoat**, a solar-powered vessel designed for environmentally conscious customers, featuring zero emissions and advanced solar technology.\n",
      "========================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [02:58<00:00, 17.87s/it]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(dataset):\n",
    "    try:\n",
    "        agent.reset()\n",
    "        \n",
    "        with tru_agent as recording:\n",
    "            agent.query(item.get('question'))\n",
    "        record_agent = recording.get()\n",
    "        \n",
    "        # wait until all the feedback function are finished\n",
    "        for feedback, result in record_agent.wait_for_feedback_results().items():\n",
    "            logging.info(f'{feedback.name}: {result.result}')\n",
    "    except Exception as e:\n",
    "        logging.error(e)\n",
    "        traceback.format_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e56194c2-facd-46e3-83fe-9563786518c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini-custom-retriever</th>\n",
       "      <th>base</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.702693</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini-custom-retriever-added-tool-inputs</th>\n",
       "      <th>base</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.548889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.007236</td>\n",
       "      <td>0.001114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3.2-3B-custom-retriever-added-tool-inputs</th>\n",
       "      <th>base</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.616111</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>6.842885</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini-default-retriever</th>\n",
       "      <th>base</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>5.125279</td>\n",
       "      <td>0.000534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-4o-mini-default-retriever-added-tool-inputs</th>\n",
       "      <th>base</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>7.523859</td>\n",
       "      <td>0.000534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3.2-3B-default-retriever-added-tool-inputs</th>\n",
       "      <th>base</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>7.137055</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3.2-3B-custom-retriever</th>\n",
       "      <th>base</th>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.510251</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>8.730055</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama-3.2-3B-default-retriever</th>\n",
       "      <th>base</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>8.830180</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Answer Relevance  \\\n",
       "app_name                                         app_version                     \n",
       "gpt-4o-mini-custom-retriever                     base                 1.000000   \n",
       "gpt-4o-mini-custom-retriever-added-tool-inputs   base                 1.000000   \n",
       "llama-3.2-3B-custom-retriever-added-tool-inputs  base                 0.900000   \n",
       "gpt-4o-mini-default-retriever                    base                 0.800000   \n",
       "gpt-4o-mini-default-retriever-added-tool-inputs  base                 0.800000   \n",
       "llama-3.2-3B-default-retriever-added-tool-inputs base                 0.700000   \n",
       "llama-3.2-3B-custom-retriever                    base                 0.541667   \n",
       "llama-3.2-3B-default-retriever                   base                 0.428571   \n",
       "\n",
       "                                                              Context Relevance  \\\n",
       "app_name                                         app_version                      \n",
       "gpt-4o-mini-custom-retriever                     base                  0.588889   \n",
       "gpt-4o-mini-custom-retriever-added-tool-inputs   base                  0.548889   \n",
       "llama-3.2-3B-custom-retriever-added-tool-inputs  base                  0.616111   \n",
       "gpt-4o-mini-default-retriever                    base                  0.716667   \n",
       "gpt-4o-mini-default-retriever-added-tool-inputs  base                  0.716667   \n",
       "llama-3.2-3B-default-retriever-added-tool-inputs base                  0.558333   \n",
       "llama-3.2-3B-custom-retriever                    base                  0.510251   \n",
       "llama-3.2-3B-default-retriever                   base                  0.523810   \n",
       "\n",
       "                                                              Groundedness  \\\n",
       "app_name                                         app_version                 \n",
       "gpt-4o-mini-custom-retriever                     base             1.000000   \n",
       "gpt-4o-mini-custom-retriever-added-tool-inputs   base             1.000000   \n",
       "llama-3.2-3B-custom-retriever-added-tool-inputs  base             0.900000   \n",
       "gpt-4o-mini-default-retriever                    base             0.793333   \n",
       "gpt-4o-mini-default-retriever-added-tool-inputs  base             0.793333   \n",
       "llama-3.2-3B-default-retriever-added-tool-inputs base             0.833333   \n",
       "llama-3.2-3B-custom-retriever                    base             0.708333   \n",
       "llama-3.2-3B-default-retriever                   base             0.714286   \n",
       "\n",
       "                                                                latency  \\\n",
       "app_name                                         app_version              \n",
       "gpt-4o-mini-custom-retriever                     base          6.702693   \n",
       "gpt-4o-mini-custom-retriever-added-tool-inputs   base         11.007236   \n",
       "llama-3.2-3B-custom-retriever-added-tool-inputs  base          6.842885   \n",
       "gpt-4o-mini-default-retriever                    base          5.125279   \n",
       "gpt-4o-mini-default-retriever-added-tool-inputs  base          7.523859   \n",
       "llama-3.2-3B-default-retriever-added-tool-inputs base          7.137055   \n",
       "llama-3.2-3B-custom-retriever                    base          8.730055   \n",
       "llama-3.2-3B-default-retriever                   base          8.830180   \n",
       "\n",
       "                                                              total_cost  \n",
       "app_name                                         app_version              \n",
       "gpt-4o-mini-custom-retriever                     base           0.001112  \n",
       "gpt-4o-mini-custom-retriever-added-tool-inputs   base           0.001114  \n",
       "llama-3.2-3B-custom-retriever-added-tool-inputs  base           0.000000  \n",
       "gpt-4o-mini-default-retriever                    base           0.000534  \n",
       "gpt-4o-mini-default-retriever-added-tool-inputs  base           0.000534  \n",
       "llama-3.2-3B-default-retriever-added-tool-inputs base           0.000000  \n",
       "llama-3.2-3B-custom-retriever                    base           0.000000  \n",
       "llama-3.2-3B-default-retriever                   base           0.000000  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0d19c-2a49-4eb3-a573-a124515caea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tru.get_apps()\n",
    "# tru.delete_app(\"app_hash_8f3f218c0136495a4835614dc1bbf1be\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60bbd6-a27e-49aa-bf0b-82d937282866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae54650-9990-456d-a984-043cf9f2de64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-llamaindex-F9o6lAMf-py3.11",
   "language": "python",
   "name": "rag-llamaindex-f9o6lamf-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
