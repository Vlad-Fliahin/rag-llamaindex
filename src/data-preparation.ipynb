{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86c49766-2c56-4c05-8bae-48c18d8d2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import tomli as tomlib\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import Settings, VectorStoreIndex, get_response_synthesizer, SimpleDirectoryReader, StorageContext\n",
    "from llama_index.core.node_parser import TokenTextSplitter, SentenceSplitter\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.vector_stores.neo4jvector import Neo4jVectorStore\n",
    "from llama_index.core.indices.vector_store.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor, NERPIINodePostprocessor, PrevNextNodePostprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46de7f8-adb4-4219-8910-be72421d887a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb1421df-7506-4822-8bd7-adfdfd67c840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse configuration\n",
    "with open('../pyproject.toml', \"rb\") as file:\n",
    "    CFG = tomlib.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5fd93-1d19-4b05-881f-5281650cd983",
   "metadata": {},
   "source": [
    "## Chunks preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba58f6ad-6bc2-46b4-a338-977e3c919281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize models\n",
    "embed_model = OpenAIEmbedding(\n",
    "    model=CFG['configuration']['models']['embedding_model'],\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    dimensions=CFG['configuration']['embedding_dimension']\n",
    ")\n",
    "\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "780a9430-fbdc-4e82-bd65-6d795842f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get documents paths\n",
    "document_paths = [Path(CFG['configuration']['data']['raw_data_path']) / document for document in CFG['configuration']['data']['source_docs']]\n",
    "\n",
    "# initialize a file reader\n",
    "reader = SimpleDirectoryReader(input_files=document_paths)\n",
    "\n",
    "# load documents into LlamaIndex Documents\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d507c59-801d-482c-9871-93e7b1f4a8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def id_func(index, document):\n",
    "    \"\"\"Creates a specific chunk id\"\"\"\n",
    "    document_name = Path(document.metadata['file_name']).stem\n",
    "    return f\"{document_name}-{index}\"\n",
    "\n",
    "# chunks splitter\n",
    "parser = SentenceSplitter(\n",
    "    chunk_size=CFG['configuration']['chunk_size'],\n",
    "    chunk_overlap=CFG['configuration']['chunk_overlap'],\n",
    "    separator=CFG['configuration']['separator'],\n",
    "    id_func=id_func\n",
    ")\n",
    "\n",
    "# parse documents into nodes (chunks)\n",
    "nodes = parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2339c739-96f1-4c1a-a448-ad85225a00d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57613fa4-3cb3-4750-94be-c982e825f523",
   "metadata": {},
   "source": [
    "## DB setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d14902c-d8e0-4230-8af7-e16b1c7574b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100% 36/36 [00:01<00:00, 27.53it/s]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (row) { ... }} {position: line: 1, column: 21, offset: 20} for query: \"UNWIND $data AS row CALL { WITH row MERGE (c:`Chunk` {id: row.id}) WITH c, row CALL db.create.setVectorProperty(c, 'embedding', row.embedding) YIELD node SET c.`text` = row.text SET c += row.metadata } IN TRANSACTIONS OF 1000 ROWS\"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 80, offset: 79} for query: \"UNWIND $data AS row CALL { WITH row MERGE (c:`Chunk` {id: row.id}) WITH c, row CALL db.create.setVectorProperty(c, 'embedding', row.embedding) YIELD node SET c.`text` = row.text SET c += row.metadata } IN TRANSACTIONS OF 1000 ROWS\"\n"
     ]
    }
   ],
   "source": [
    "neo4j_vector = Neo4jVectorStore(\n",
    "    username=CFG['configuration']['db']['username'],\n",
    "    password=CFG['configuration']['db']['password'],\n",
    "    url=CFG['configuration']['db']['url'],\n",
    "    embedding_dimension=CFG['configuration']['embedding_dimension'],\n",
    "    hybrid_search=CFG['configuration']['hybrid_search']\n",
    ")\n",
    "\n",
    "# setup context\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=neo4j_vector\n",
    ")\n",
    "\n",
    "# populate DB with nodes\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8422e-0d51-464f-b895-40672b89c1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-llamaindex-poetry",
   "language": "python",
   "name": "rag-llamaindex-f9o6lamf-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
